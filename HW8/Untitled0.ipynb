{
 "metadata": {
  "name": "Untitled0"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import statsmodels.api as sm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.read_csv('clean.csv')\n",
      "df = sm.add_constant(df, prepend=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###(a) Estimate an OLS regression of log wage (*lwage*) on *educ, exper, expersq, black, south, smsa, reg661* through *reg668* and *smsa66*. Compare the results with Column (1) of the replication document.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "endog_a = df['lwage']\n",
      "exog = ['const', 'educ', 'exper', 'expersq', 'black', 'south', 'smsa', 'reg661', 'reg662', 'reg663', \n",
      "        'reg664', 'reg665', 'reg666', 'reg667', 'reg668', 'smsa66']\n",
      "\n",
      "exog_a = df[exog]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_a = sm.OLS(endog_a, exog_a)\n",
      "results_a = model_a.fit()\n",
      "\n",
      "print(results_a.summary())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "                            OLS Regression Results                            \n",
        "==============================================================================\n",
        "Dep. Variable:                  lwage   R-squared:                       0.300\n",
        "Model:                            OLS   Adj. R-squared:                  0.296\n",
        "Method:                 Least Squares   F-statistic:                     85.48\n",
        "Date:                Tue, 04 Dec 2012   Prob (F-statistic):          1.74e-218\n",
        "Time:                        17:19:48   Log-Likelihood:                -1288.8\n",
        "No. Observations:                3010   AIC:                             2610.\n",
        "Df Residuals:                    2994   BIC:                             2706.\n",
        "Df Model:                          15                                         \n",
        "==============================================================================\n",
        "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
        "------------------------------------------------------------------------------\n",
        "const          4.7394      0.072     66.259      0.000         4.599     4.880\n",
        "educ           0.0747      0.003     21.351      0.000         0.068     0.082\n",
        "exper          0.0848      0.007     12.806      0.000         0.072     0.098\n",
        "expersq       -0.0023      0.000     -7.223      0.000        -0.003    -0.002\n",
        "black         -0.1990      0.018    -10.906      0.000        -0.235    -0.163\n",
        "south         -0.1480      0.026     -5.695      0.000        -0.199    -0.097\n",
        "smsa           0.1364      0.020      6.785      0.000         0.097     0.176\n",
        "reg661        -0.1186      0.039     -3.054      0.002        -0.195    -0.042\n",
        "reg662        -0.0222      0.028     -0.786      0.432        -0.078     0.033\n",
        "reg663         0.0260      0.027      0.949      0.343        -0.028     0.080\n",
        "reg664        -0.0635      0.036     -1.780      0.075        -0.133     0.006\n",
        "reg665         0.0095      0.036      0.262      0.794        -0.061     0.080\n",
        "reg666         0.0219      0.040      0.547      0.584        -0.057     0.101\n",
        "reg667        -0.0006      0.039     -0.015      0.988        -0.078     0.077\n",
        "reg668        -0.1750      0.046     -3.777      0.000        -0.266    -0.084\n",
        "smsa66         0.0262      0.019      1.349      0.177        -0.012     0.064\n",
        "==============================================================================\n",
        "Omnibus:                       59.717   Durbin-Watson:                   1.880\n",
        "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               71.222\n",
        "Skew:                          -0.282   Prob(JB):                     3.42e-16\n",
        "Kurtosis:                       3.501   Cond. No.                     1.59e+03\n",
        "==============================================================================\n",
        "\n",
        "The condition number is large, 1.59e+03. This might indicate that there are\n",
        "strong multicollinearity or other numerical problems.\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###b:  Estimate a reduced form first stage regression of education on all the explanatory variables plus the dummy nearc4. Do *educ* and *nearc4* have (practical, statistical) significant partial correlation?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Education and proximity to a college do seem to have a statistically significant partial autocorrelation. The economic importance is less clear.  Being \"close\" to a college raises your expected education by about $\\frac{1}{3}$ of a year. Or, a bit under one semester."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "endog_b = df['educ']\n",
      "exog_b = exog_a.drop('educ', axis=1).join(df['nearc4'])\n",
      "\n",
      "model_b = sm.OLS(endog_b, exog_b)\n",
      "results_b = model_b.fit()\n",
      "print(results_b.summary())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "                            OLS Regression Results                            \n",
        "==============================================================================\n",
        "Dep. Variable:                   educ   R-squared:                       0.477\n",
        "Model:                            OLS   Adj. R-squared:                  0.474\n",
        "Method:                 Least Squares   F-statistic:                     182.1\n",
        "Date:                Tue, 04 Dec 2012   Prob (F-statistic):               0.00\n",
        "Time:                        17:31:10   Log-Likelihood:                -6258.5\n",
        "No. Observations:                3010   AIC:                         1.255e+04\n",
        "Df Residuals:                    2994   BIC:                         1.265e+04\n",
        "Df Model:                          15                                         \n",
        "==============================================================================\n",
        "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
        "------------------------------------------------------------------------------\n",
        "const         16.8485      0.211     79.805      0.000        16.435    17.262\n",
        "exper         -0.4125      0.034    -12.241      0.000        -0.479    -0.346\n",
        "expersq        0.0009      0.002      0.526      0.599        -0.002     0.004\n",
        "black         -0.9355      0.094     -9.981      0.000        -1.119    -0.752\n",
        "south         -0.0516      0.135     -0.381      0.703        -0.317     0.214\n",
        "smsa           0.4022      0.105      3.837      0.000         0.197     0.608\n",
        "reg661        -0.2103      0.202     -1.039      0.299        -0.607     0.187\n",
        "reg662        -0.2889      0.147     -1.961      0.050        -0.578 -1.05e-05\n",
        "reg663        -0.2382      0.143     -1.670      0.095        -0.518     0.041\n",
        "reg664        -0.0931      0.186     -0.501      0.617        -0.458     0.272\n",
        "reg665        -0.4829      0.188     -2.566      0.010        -0.852    -0.114\n",
        "reg666        -0.5131      0.210     -2.448      0.014        -0.924    -0.102\n",
        "reg667        -0.4271      0.206     -2.077      0.038        -0.830    -0.024\n",
        "reg668         0.3136      0.242      1.298      0.194        -0.160     0.787\n",
        "smsa66         0.0255      0.106      0.241      0.810        -0.182     0.233\n",
        "nearc4         0.3199      0.088      3.641      0.000         0.148     0.492\n",
        "==============================================================================\n",
        "Omnibus:                       15.758   Durbin-Watson:                   1.762\n",
        "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               15.971\n",
        "Skew:                           0.177   Prob(JB):                     0.000340\n",
        "Kurtosis:                       2.954   Cond. No.                     1.49e+03\n",
        "==============================================================================\n",
        "\n",
        "The condition number is large, 1.49e+03. This might indicate that there are\n",
        "strong multicollinearity or other numerical problems.\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###(c) Estimate an IV regression of *lwage* on the explanatory variables, using *nearc4* as an instrument for *educ*. Compare confidence intervals for $\\hat{\\beta}_{educ}$ from this regression and the OLS regression from part (a). Also compare this to column (2) in the replication document.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "From part (a), $\\hat{\\beta}_{educ}$ had a 95% confidence interval of (0.068, 0.082).\n",
      "\n",
      "From the IV regression (below), we find a 95% confidence interval of (0.021, 0.242)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "endog_x = df['educ']\n",
      "exog_x = df[['const', 'nearc4', 'exper', 'expersq', 'black', 'south',\n",
      "        'smsa', 'reg661', 'reg662', 'reg663', 'reg664', 'reg665',\n",
      "        'reg666', 'reg667', 'reg668', 'smsa66']]\n",
      "\n",
      "\n",
      "model_x = sm.OLS(endog_x, exog_x)\n",
      "results_x = model_x.fit()\n",
      "df['educ_hats'] = results_x.fittedvalues\n",
      "\n",
      "endog_c = df['lwage']\n",
      "\n",
      "# replace educ with IV.\n",
      "exog_c = df[['const', 'educ_hats', 'exper', 'expersq', 'black', 'south',\n",
      "        'smsa', 'reg661', 'reg662', 'reg663', 'reg664', 'reg665',\n",
      "        'reg666', 'reg667', 'reg668', 'smsa66']]\n",
      "\n",
      "model_c = sm.OLS(endog_c, exog_c)\n",
      "results_c = model_c.fit()\n",
      "\n",
      "print(results_c).summary()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "                            OLS Regression Results                            \n",
        "==============================================================================\n",
        "Dep. Variable:                  lwage   R-squared:                       0.195\n",
        "Model:                            OLS   Adj. R-squared:                  0.191\n",
        "Method:                 Least Squares   F-statistic:                     48.25\n",
        "Date:                Tue, 04 Dec 2012   Prob (F-statistic):          9.82e-129\n",
        "Time:                        17:22:36   Log-Likelihood:                -1499.4\n",
        "No. Observations:                3010   AIC:                             3031.\n",
        "Df Residuals:                    2994   BIC:                             3127.\n",
        "Df Model:                          15                                         \n",
        "==============================================================================\n",
        "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
        "------------------------------------------------------------------------------\n",
        "const          3.7740      0.961      3.926      0.000         1.889     5.659\n",
        "educ_hats      0.1315      0.057      2.327      0.020         0.021     0.242\n",
        "exper          0.1083      0.024      4.451      0.000         0.061     0.156\n",
        "expersq       -0.0023      0.000     -6.810      0.000        -0.003    -0.002\n",
        "black         -0.1468      0.055     -2.649      0.008        -0.255    -0.038\n",
        "south         -0.1447      0.028     -5.157      0.000        -0.200    -0.090\n",
        "smsa           0.1118      0.033      3.435      0.001         0.048     0.176\n",
        "reg661        -0.1078      0.043     -2.508      0.012        -0.192    -0.024\n",
        "reg662        -0.0070      0.034     -0.208      0.835        -0.073     0.059\n",
        "reg663         0.0404      0.033      1.238      0.216        -0.024     0.105\n",
        "reg664        -0.0579      0.039     -1.498      0.134        -0.134     0.018\n",
        "reg665         0.0385      0.048      0.797      0.426        -0.056     0.133\n",
        "reg666         0.0551      0.054      1.017      0.309        -0.051     0.161\n",
        "reg667         0.0268      0.050      0.533      0.594        -0.072     0.125\n",
        "reg668        -0.1909      0.052     -3.661      0.000        -0.293    -0.089\n",
        "smsa66         0.0185      0.022      0.834      0.404        -0.025     0.062\n",
        "==============================================================================\n",
        "Omnibus:                       37.068   Durbin-Watson:                   1.844\n",
        "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               43.554\n",
        "Skew:                          -0.207   Prob(JB):                     3.49e-10\n",
        "Kurtosis:                       3.419   Cond. No.                     1.70e+04\n",
        "==============================================================================\n",
        "\n",
        "The condition number is large, 1.7e+04. This might indicate that there are\n",
        "strong multicollinearity or other numerical problems.\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###(d) Now add *nearc2* to *nearc4* as an instrument for education. Are the proximity variables well related to *educ*? Is there statistical evidence to suggest that *educ* is indeed endogenous and *nearc2* and *nearc4* are exogenous instruments? How does the 2SLS estimate of $\\hat{\\beta}_{educ}$ compare to the OLS and simple IV estimates?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$nearc4$ appears to be related to educ, while $nearc2$ does not (see the first output below).\n",
      "\n",
      "J-Test:\n",
      "\n",
      "Wald-Test:\n",
      "\n",
      "From the second output below, we find that $\\hat{\\beta}^{IV}_{educ}$ is now 0.3529 (and significant).  From above we estimated $\\hat{\\beta}_{educ}$ to be 0.0747.  So our estimate has increased."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "endog_x = df['educ']\n",
      "exog_x2 = df[['const', 'nearc2', 'nearc4', 'exper', 'expersq', 'black',\n",
      "        'south', 'smsa', 'reg661', 'reg662', 'reg663', 'reg664', 'reg665',\n",
      "        'reg666', 'reg667', 'reg668', 'smsa66']]\n",
      "\n",
      "model_x2 = sm.OLS(endog_x, exog_x2)\n",
      "results_x2 = model_x2.fit()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(results_x2).summary()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "                            OLS Regression Results                            \n",
        "==============================================================================\n",
        "Dep. Variable:                   educ   R-squared:                       0.478\n",
        "Model:                            OLS   Adj. R-squared:                  0.475\n",
        "Method:                 Least Squares   F-statistic:                     171.0\n",
        "Date:                Tue, 04 Dec 2012   Prob (F-statistic):               0.00\n",
        "Time:                        17:23:56   Log-Likelihood:                -6257.2\n",
        "No. Observations:                3010   AIC:                         1.255e+04\n",
        "Df Residuals:                    2993   BIC:                         1.265e+04\n",
        "Df Model:                          16                                         \n",
        "==============================================================================\n",
        "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
        "------------------------------------------------------------------------------\n",
        "const         16.7731      0.216     77.528      0.000        16.349    17.197\n",
        "nearc2         0.1230      0.077      1.589      0.112        -0.029     0.275\n",
        "nearc4         0.3206      0.088      3.650      0.000         0.148     0.493\n",
        "exper         -0.4123      0.034    -12.237      0.000        -0.478    -0.346\n",
        "expersq        0.0008      0.002      0.514      0.607        -0.002     0.004\n",
        "black         -0.9452      0.094    -10.065      0.000        -1.129    -0.761\n",
        "south         -0.0419      0.136     -0.309      0.757        -0.308     0.224\n",
        "smsa           0.4014      0.105      3.830      0.000         0.196     0.607\n",
        "reg661        -0.1688      0.204     -0.827      0.408        -0.569     0.231\n",
        "reg662        -0.2690      0.148     -1.820      0.069        -0.559     0.021\n",
        "reg663        -0.1902      0.146     -1.305      0.192        -0.476     0.096\n",
        "reg664        -0.0377      0.189     -0.199      0.842        -0.409     0.333\n",
        "reg665        -0.4371      0.190     -2.297      0.022        -0.810    -0.064\n",
        "reg666        -0.5022      0.210     -2.395      0.017        -0.913    -0.091\n",
        "reg667        -0.3775      0.208     -1.816      0.070        -0.785     0.030\n",
        "reg668         0.3820      0.245      1.557      0.120        -0.099     0.863\n",
        "smsa66      7.825e-05      0.107      0.001      0.999        -0.210     0.210\n",
        "==============================================================================\n",
        "Omnibus:                       15.186   Durbin-Watson:                   1.764\n",
        "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               15.382\n",
        "Skew:                           0.174   Prob(JB):                     0.000457\n",
        "Kurtosis:                       2.960   Cond. No.                     1.52e+03\n",
        "==============================================================================\n",
        "\n",
        "The condition number is large, 1.52e+03. This might indicate that there are\n",
        "strong multicollinearity or other numerical problems.\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Reuse endog_x from c;\n",
      "exog_x2 = df[['const', 'nearc2', 'nearc4', 'exper', 'expersq', 'black',\n",
      "        'south', 'smsa', 'reg661', 'reg662', 'reg663', 'reg664', 'reg665',\n",
      "        'reg666', 'reg667', 'reg668', 'smsa66']]\n",
      "\n",
      "model_x2 = sm.OLS(endog_x, exog_x2)\n",
      "results_x2 = model_x2.fit()\n",
      "df['educ_hats2'] = results_x2.fittedvalues\n",
      "\n",
      "exog_d = df[['const', 'nearc2', 'nearc4', 'exper', 'expersq', 'black',\n",
      "        'south', 'smsa', 'reg661', 'reg662', 'reg663', 'reg664', 'reg665',\n",
      "        'reg666', 'reg667', 'reg668', 'smsa66'] + ['educ_hats2']]\n",
      "\n",
      "model_d = sm.OLS(endog_c, exog_d)\n",
      "results_d = model_d.fit()\n",
      "\n",
      "print(results_d.summary())\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "                            OLS Regression Results                            \n",
        "==============================================================================\n",
        "Dep. Variable:                  lwage   R-squared:                       0.196\n",
        "Model:                            OLS   Adj. R-squared:                  0.192\n",
        "Method:                 Least Squares   F-statistic:                     45.62\n",
        "Date:                Tue, 04 Dec 2012   Prob (F-statistic):          5.81e-129\n",
        "Time:                        17:24:01   Log-Likelihood:                -1496.8\n",
        "No. Observations:                3010   AIC:                             3028.\n",
        "Df Residuals:                    2993   BIC:                             3130.\n",
        "Df Model:                          16                                         \n",
        "==============================================================================\n",
        "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
        "------------------------------------------------------------------------------\n",
        "const          0.0485      0.003     14.852      0.000         0.042     0.055\n",
        "nearc2        -0.0076      0.016     -0.473      0.636        -0.039     0.024\n",
        "nearc4        -0.0709      0.018     -3.886      0.000        -0.107    -0.035\n",
        "exper          0.1996      0.006     31.971      0.000         0.187     0.212\n",
        "expersq       -0.0025      0.000     -7.474      0.000        -0.003    -0.002\n",
        "black          0.0609      0.020      3.113      0.002         0.023     0.099\n",
        "south         -0.1338      0.028     -4.802      0.000        -0.188    -0.079\n",
        "smsa           0.0228      0.022      1.050      0.294        -0.020     0.065\n",
        "reg661        -0.0638      0.042     -1.526      0.127        -0.146     0.018\n",
        "reg662         0.0557      0.030      1.853      0.064        -0.003     0.115\n",
        "reg663         0.0902      0.030      3.037      0.002         0.032     0.148\n",
        "reg664        -0.0407      0.039     -1.048      0.295        -0.117     0.035\n",
        "reg665         0.1425      0.039      3.689      0.000         0.067     0.218\n",
        "reg666         0.1680      0.043      3.946      0.000         0.085     0.251\n",
        "reg667         0.1183      0.042      2.791      0.005         0.035     0.201\n",
        "reg668        -0.2645      0.051     -5.206      0.000        -0.364    -0.165\n",
        "smsa66         0.0145      0.022      0.657      0.511        -0.029     0.058\n",
        "educ_hats2     0.3529      0.003    130.405      0.000         0.348     0.358\n",
        "==============================================================================\n",
        "Omnibus:                       38.768   Durbin-Watson:                   1.847\n",
        "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               45.067\n",
        "Skew:                          -0.217   Prob(JB):                     1.64e-10\n",
        "Kurtosis:                       3.413   Cond. No.                     5.08e+09\n",
        "==============================================================================\n",
        "\n",
        "strong multicollinearity problems or that the design matrix is singular.\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###(e) IQ scores are available for some of the men in the sample. Are *iq* and *nearc4* correlated?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Yes the two are correlated."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df[['iq', 'nearc4']].corr()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>iq</th>\n",
        "      <th>nearc4</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <td><strong>iq</strong></td>\n",
        "      <td> 1.000000</td>\n",
        "      <td> 0.076522</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td><strong>nearc4</strong></td>\n",
        "      <td> 0.076522</td>\n",
        "      <td> 1.000000</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "              iq    nearc4\n",
        "iq      1.000000  0.076522\n",
        "nearc4  0.076522  1.000000"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Valid observations\n",
      "len(df['iq']) - sum(df['iq'].isnull())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "2061"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###(f) Regress *iq* on *nearc4*, *smsa66*, *reg661*, *reg662* and *reg669*. Are *iq* and *nearc4* partially correlated? What does this imply about the addition of location and region variables in the IV equation when *nearc4* is an instrument?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "endog_f = df['iq'].dropna()\n",
      "idx = endog_f.index\n",
      "exog_f = df[['const', 'nearc4', 'smsa66', 'reg661',\n",
      "                                'reg662', 'reg669']].ix[idx]\n",
      "\n",
      "model_f = sm.OLS(endog_f, exog_f)\n",
      "results_f = model_f.fit()\n",
      "print(results_f.summary())\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "                            OLS Regression Results                            \n",
        "==============================================================================\n",
        "Dep. Variable:                     iq   R-squared:                       0.030\n",
        "Model:                            OLS   Adj. R-squared:                  0.028\n",
        "Method:                 Least Squares   F-statistic:                     12.79\n",
        "Date:                Tue, 04 Dec 2012   Prob (F-statistic):           2.87e-12\n",
        "Time:                        17:44:23   Log-Likelihood:                -8531.1\n",
        "No. Observations:                2061   AIC:                         1.707e+04\n",
        "Df Residuals:                    2055   BIC:                         1.711e+04\n",
        "Df Model:                           5                                         \n",
        "==============================================================================\n",
        "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
        "------------------------------------------------------------------------------\n",
        "const         99.3847      0.702    141.642      0.000        98.009   100.761\n",
        "nearc4         0.8681      0.822      1.056      0.291        -0.743     2.480\n",
        "smsa66         1.3545      0.803      1.687      0.092        -0.220     2.929\n",
        "reg661         4.7681      1.547      3.083      0.002         1.735     7.802\n",
        "reg662         5.8081      0.902      6.441      0.000         4.040     7.577\n",
        "reg669         1.8447      1.152      1.602      0.109        -0.414     4.103\n",
        "==============================================================================\n",
        "Omnibus:                       31.071   Durbin-Watson:                   1.779\n",
        "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               32.090\n",
        "Skew:                          -0.302   Prob(JB):                     1.08e-07\n",
        "Kurtosis:                       3.096   Cond. No.                         6.96\n",
        "==============================================================================\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Since the effects of $iq$ are picked up in the error term, we would not want our instruments to be (partially) correlated with $iq$, once we've controlled for the exogenous variables.  The high p-value on $nearc4$ is encouraging since it does *not* indicate that our variables *are* correlated with the errors from the initial regression. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}